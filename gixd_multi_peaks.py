# -*- coding: utf-8 -*-
"""gixd_multi_peaks.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nhuyrqODljUmz0Zl0KgiMBaQzIu_bH6W
"""

from matplotlib import markers
import numpy as np
import pandas as pd
from lmfit.models import LorentzianModel, GaussianModel
import matplotlib.pyplot as plt
from scipy import signal
import itertools

# file input and assign
path = '/Users/dayeen/Downloads/'
filenames = ['DPPC_Chol_5%_chol_scan8485_qxy_gid','DPPC_chol9010_scan69_70_qxy_gid','DPPC_chol8020_scan72_73_qxy_gid']

# legends for data
data_legends = ['5 Chol', '10 Chol', '20 Chol']


#fit declaration
gauss_mod = GaussianModel(prefix='gauss_')
lorentz1 = LorentzianModel(prefix='l1_')
lorentz2 = LorentzianModel(prefix='l2_')

#color
color_pallate = ['#FF1F5B', '#009ADE', '#AF58BA', '#FFC61E','#F28522']

def index_of(array_value, peak_value):
    """return index of array *at or below* peak_value """
    if peak_value < min(array_value):
        return 0
    return max(np.where(array_value <= peak_value)[0])
    
def get_peaks(x, y):
    #rough peak positions
    r_peak1 = index_of(x, 1.3)
    r_peak2 = index_of(x, 1.47)
    r_peak3 = index_of(x, 1.67)

    pars1 = gauss_mod.guess(y[:r_peak1], x=x[:r_peak1])
    pars2 = lorentz1.guess(y[r_peak1:r_peak2], x=x[r_peak1:r_peak2])
    pars3 = lorentz2.guess(y[r_peak2:r_peak3], x=x[r_peak2:r_peak3])

    pars_peaks = pars1 + pars2 + pars3
    mod_peaks = lorentz1 + lorentz2 + gauss_mod

    out_peaks = mod_peaks.fit(y, pars_peaks, x=x)

    #print output
    # print(out_peaks.fit_report(min_correl=0.5))

    #plot with fit
    # plt.plot(x, out_peaks.init_fit, 'k--', label='initial fit')
    plt.plot(x, out_peaks.best_fit, color=color_pallate[filenames.index(i)], label=' ')# label=data_legends[filenames.index(i)]
    plt.legend(loc='best')
    
    #assign values to variables for calculation
    peak1 = out_peaks.params['l1_center'].value
    peak2 = out_peaks.params['l2_center'].value
    fwhm1 = out_peaks.params['l1_fwhm'].value
    fwhm2 = out_peaks.params['l2_fwhm'].value
    return peak1, peak2, fwhm1, fwhm2

#create dataframe from files
for i in filenames:
    df = (pd.read_csv(path +i +'.txt',delimiter='\t',names=['q','intensity','error']))
    X = df['q'].values
    Y = df['intensity'].values
    yerr = df['error'].values

    Y_fix=signal.detrend(Y)-min(signal.detrend(Y))

    x = X
    y = Y_fix

    # for plotting
    markers = ['o', 'v', 'p', 'h', 'D']
    # plt.figure(dpi=100)
    plt.plot(x, y, marker = markers[filenames.index(i)], linestyle= 'none', label=data_legends[filenames.index(i)], color=color_pallate[filenames.index(i)])
    plt.xlabel('$q_{xy}$')
    plt.ylabel('Intensity')
    plt.grid(linestyle=':')

    # calculation
    result = get_peaks(x,y)
    out_peak1 = result[0]
    out_peak2 = result[1]
    out_fwhm1 = result[2]
    out_fwhm2 = result[3]

    name = data_legends[filenames.index(i)]
    correlation_length1 = (0.9*2*np.pi)/np.sqrt(out_fwhm1**2-0.0014**2)
    correlation_length2 = (0.9*2*np.pi)/np.sqrt(out_fwhm2**2-0.0014**2)
    d_spacing_a = 2*np.pi/out_peak1
    d_spacing_b = 2*np.pi/out_peak2
    Area_unit_cell_a = (np.sqrt(3)/2)*d_spacing_a**2

    print(
    '\nSample: ', name,   
    '\npeak1 = ',out_peak1,
    '\npeak2 = ', out_peak2,
    '\ncorrelation1 = ',correlation_length1, 
    '\ncorrelation2 = ',correlation_length2,
    '\nd-spacing_a = ',d_spacing_a,
    '\nd-spacing_a = ',d_spacing_b,
    '\nArea_unitcell_a = ',Area_unit_cell_a
    )
plt.show()